# Multimodal AI (image, video, audio) news

| Title | Summary | Topics | Week |
| --- | --- | --- | --- |
| [Meta releases Llama 3.2](https://ai.meta.com/blog/llama-3-2-connect-2024-vision-edge-mobile-devices/) 🟢 | Llama 3.2 features advanced AI models, including vision LLMs (11B and 90B) and lightweight text-only models (1B and 3B), optimized for edge and mobile devices. These models excel in tasks such as summarization and image understanding, supporting extensive token lengths. | [Model release 🎉](Topic_Model_release.md), [LLaMA 🦙](Topic_LLaMA.md), [Meta ♾](Topic_Meta.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-09-30 |
| [Mistral releases Pixtral 12B, its first multimodal model](https://techcrunch.com/2024/09/11/mistral-releases-pixtral-its-first-multimodal-model/) 🟢 | Mistral has introduced Pixtral 12B, a 12-billion-parameter multimodal AI model that processes both text and images. Building on features from their previous text model, Nemo 12B, Pixtral 12B is available for free download on GitHub and Hugging Face under an Apache 2.0 license. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Model release 🎉](Topic_Model_release.md), [Mistral 🌬️](Topic_Mistral.md) | 2024-09-16 |
| [Alibaba releases new AI model Qwen2-VL that can analyze videos more than 20 minutes long](https://venturebeat.com/ai/alibaba-releases-new-ai-model-qwen2-vl-that-can-analyze-videos-more-than-20-minutes-long/) 🟢 | Alibaba Cloud’s new AI model, Qwen2-VL, excels in video analysis and multilingual comprehension, outperforming Meta’s Llama 3.1 and Google’s Gemini-1.5 in benchmarks. It supports multiple languages and extended video content analysis, and is available in three sizes, with two being open-sourced. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Model release 🎉](Topic_Model_release.md), [Google Gemini 🌌](Topic_Google_Gemini.md) | 2024-09-09 |
| [Google rolling out Gems and Imagen 3 to Gemini Advanced](https://9to5google.com/2024/08/28/gemini-advanced-gems-imagen-3/) 🟢 | Google’s Gemini has launched Gems, a feature for custom task-oriented version creation, and Imagen 3, an advanced image generation tool that includes ethically-guided people generation, for Advanced subscribers to boost productivity and creativity. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Google Gemini 🌌](Topic_Google_Gemini.md), [Google 🔍](Topic_Google.md) | 2024-09-02 |
| [Runway’s Gen-3 Alpha Turbo is here and can make AI videos faster than you can type](https://venturebeat.com/ai/runways-gen-3-alpha-turbo-is-here-and-can-make-ai-videos-faster-than-you-can-type/) 🟢 | Runway ML introduces Gen-3 Alpha Turbo, an AI video generation model delivering 7x speed improvements and 50% cost reduction. Widely available across subscription plans, the model addresses diverse needs while promising advancements amidst ethical scrutiny, signaling Runway’s ambition for market leadership. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Model release 🎉](Topic_Model_release.md) | 2024-08-26 |
| [X’s new AI image generator will make anything from Taylor Swift in lingerie to Kamala Harris with a gun](https://www.theverge.com/2024/8/14/24220173/xai-grok-image-generator-misinformation-offensive-imges) 🔴 | Grok, xAI’s new chatbot released on Elon Musk’s platform X, enables generation of images from text prompts with minimal content restrictions. However, its production of controversial content has highlighted a stark difference in policy enforcement compared to other AI services, raising concerns about regulation and digital safety, which could impact the platform’s relationship with advertisers and attract attention from European regulators. | [AI safety 🔐](Topic_AI_safety.md), [AI for images 🖼️](Topic_AI_for_images.md), [AI regulation 📜](Topic_AI_regulation.md), [Grok 🐦](Topic_Grok.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-08-19 |
| [The AI Scientist: Towards Fully Automated Open-Ended Scientific Discovery](https://sakana.ai/ai-scientist/) 🟢 | Sakana AI has launched The AI Scientist, an automated system designed to advance scientific discovery in areas such as diffusion models and transformers. Working with leading academic partners, it can produce and assess scientific papers, offering cost savings but with current limitations including no visual capabilities and potential inaccuracies. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-08-19 |
| [Introducing SAM 2: The next generation of Meta Segment Anything Model for videos and images](https://ai.meta.com/blog/segment-anything-2/) 🟢 | Meta has launched SAM 2, an improved AI model for prompt-based real-time video and image segmentation, featuring zero-shot learning and requiring three times fewer interactions. SAM 2 is now available as open-source under the Apache 2.0 license. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Model release 🎉](Topic_Model_release.md), [Meta ♾](Topic_Meta.md) | 2024-08-06 |
| [Instagram starts letting people create AI versions of themselves](https://www.theverge.com/24209196/instagram-ai-characters-meta-ai-studio-release) 🟢 | Meta’s AI Studio has launched a new feature for Instagram and other Meta platforms, enabling users to generate AI-crafted avatars of themselves for use across social media and the web. | [AI for images 🖼️](Topic_AI_for_images.md), [Meta ♾](Topic_Meta.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-08-06 |
| [Stability AI Releases Stable Assistant Features](https://stability.ai/news/stability-ai-releases-stable-assistant-features) 🟢 | Stability AI has enhanced its Stable Assistant with new capabilities from Stable Diffusion 3, featuring “Search & Replace” for object swapping in images, alongside existing functions for image editing, upscaling, and video generation. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Stable Diffusion 🎨](Topic_Stable_Diffusion.md), [Stability AI ⚖️](Topic_Stability_AI.md) | 2024-07-15 |
| [Adept joins Amazon](https://www.adept.ai/blog/adept-update) 🟢 | The team from Adept, including its co-founders, is integrating into Amazon’s AGI division, aiming to advance general intelligence efforts. Amazon has licensed Adept’s advanced multimodal agent technology and acquired select datasets. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Amazon 🌳](Topic_Amazon.md) | 2024-07-08 |
| [YouTube now lets you request removal of AI-generated content that simulates your face or voice](https://techcrunch.com/2024/07/01/youtube-now-lets-you-request-removal-of-ai-generated-content-that-simulates-your-face-or-voice/) 🟢 | YouTube’s revised privacy policy now enables users to request the removal of deepfake content replicating their likeness if it raises privacy issues, with certain considerations for content context and public interest. | [AI safety 🔐](Topic_AI_safety.md), [AI and copyright ©️](Topic_AI_and_copyright.md), [AI regulation 📜](Topic_AI_regulation.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Google 🔍](Topic_Google.md) | 2024-07-08 |
| [Meet Figma AI: Empowering designers with intelligent tools](https://www.figma.com/blog/introducing-figma-ai/) 🟢 | Figma has launched Figma AI, a new AI-enhanced design platform featuring AI-driven search capabilities, generative text and image tools, and advanced prototyping functionalities. It’s currently in beta and free until 2024, though usage may be capped depending on the cost of tools. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-07-01 |
| [Snapchat AI turns prompts into new lens](https://www.theverge.com/2024/6/19/24181965/snapchat-ai-prompt-custom-lens) 🟢 | Snapchat has launched a feature enabling users to create custom AI-driven lenses using textual prompts, leveraging user interaction data and online activity to tailor experiences. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-07-01 |
| [Introducing Claude 3.5 Sonnet](https://www.anthropic.com/news/claude-3-5-sonnet) 🟢 | The latest Claude 3.5 Sonnet upgrade offers enhanced intelligence, increased processing speed, and improved efficiency at a competitive price, with notable advancements in reasoning, coding, and vision processing. Additionally, the newly introduced ‘Artifacts’ feature enables real-time collaboration. | [AI for coding 👨‍💻](Topic_AI_for_coding.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Claude 🖋️](Topic_Claude.md) | 2024-06-24 |
| [Introducing Gen-3 Alpha: A New Frontier for Video Generation](https://runwayml.com/blog/introducing-gen-3-alpha/) 🟢 | Runway has launched Gen-3 Alpha, an advanced AI capable of generating videos and images from text and images. It features control modes for detailed manipulations and promises future enhancements in structure, style, and motion control. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-06-24 |
| [Indian election was awash in deepfakes — but AI was a net positive for democracy](https://theconversation.com/indian-election-was-awash-in-deepfakes-but-ai-was-a-net-positive-for-democracy-231795) 🟢 | India’s 2024 elections saw AI advancements in voter engagement through deepfake communication and real-time multi-language translation. Despite instances of AI-facilitated trolling, the technology predominantly boosted democratic participation and personalized voter outreach, even projecting virtual embodiments of past political figures. | [AI safety 🔐](Topic_AI_safety.md), [AI regulation 📜](Topic_AI_regulation.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-06-24 |
| [Generating audio for video](https://deepmind.google/discover/blog/generating-audio-for-video/) 🟢 | DeepMind has created a V2A (Video-to-Audio) system using a diffusion-based AI model for generating synchronized audio for silent videos, guided by visual and textual cues to produce lifelike sound environments. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [DeepMind 🧩](Topic_DeepMind.md) | 2024-06-24 |
| [Luma Dream Machine](https://lumalabs.ai/dream-machine) 🟢 | The Luma Dream Machine by Lumalabs is an AI model designed for synthesizing high-quality, realistic videos from text and images, leveraging a transformer-based method optimized for video content. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [AI for images 🖼️](Topic_AI_for_images.md) | 2024-06-17 |
| [Stability AI releases a sound generator](https://techcrunch.com/2024/06/05/stability-ai-releases-a-sound-generator/) 🟢 | Stability AI has launched “Stable Audio Open,” an AI model that generates sound from text descriptions using royalty-free samples, geared towards non-commercial use. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Model release 🎉](Topic_Model_release.md), [Stability AI ⚖️](Topic_Stability_AI.md) | 2024-06-10 |
| [OpenAI releases GPT-4o](https://openai.com/index/spring-update/) 🟢 | OpenAI released the new model GPT-4o, capable of processing and generating text, audio, and image inputs and outputs. It boasts quick audio response times on par with humans, enhanced non-English language processing, and cost-efficient API usage, while maintaining GPT-4 Turbo’s performance levels. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Model release 🎉](Topic_Model_release.md), [GPT-4 and GPT-4 turbo 🚀](Topic_GPT-4_and_GPT-4_turbo.md), [OpenAI 🌟](Topic_OpenAI.md) | 2024-05-21 |
| [100 things Google announced at I/O 2024](https://blog.google/technology/ai/google-io-2024-100-announcements/) 🟢 | At Google I/O 2024, notable AI developments were announced such as Gemini 1.5 models, Trillium TPU, and enhanced AI in Google Search. Key introductions include Imagen 3 for image creation, Veo for video generation, and upgraded features in the Gemini app for premium users, alongside new generative media tools. | [Google Gemini 🌌](Topic_Google_Gemini.md), [Google 🔍](Topic_Google.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [AI for images 🖼️](Topic_AI_for_images.md), [AI Chips and GPUs 🖥️](Topic_AI_Chips_and_GPUs.md) | 2024-05-21 |
| [OpenAI CEO Sam Altman says GPT-4 is the dumbest AI model you’ll ever have to use again](https://the-decoder.com/openai-ceo-sam-altman-promises-ai-models-that-far-surpass-gpt-4/) 🟢 | OpenAI’s Sam Altman considers GPT-4 the most rudimentary AI that users will encounter as the company progresses towards more sophisticated models like GPT-5, which is expected to feature enhanced abilities such as video generation. He foresees AI developing into highly efficient assistants, performing tasks and providing solutions effortlessly. | [GPT-4 and GPT-4 turbo 🚀](Topic_GPT-4_and_GPT-4_turbo.md), [GPT-5 🔮](Topic_GPT-5.md), [OpenAI 🌟](Topic_OpenAI.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-05-06 |
| [Pro music video powered by OpenAI’s Sora released in a world-first](https://interestingengineering.com/culture/sora-powered-music-video) 🟢 | Paul Trillo directed the official music video for Washed Out’s “The Hardest Part” using OpenAI’s Sora, a text-to-video AI, producing 700 clips of which 55 were used. The project has stirred ethical discussions within the AI industry. | [AI and copyright ©️](Topic_AI_and_copyright.md), [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI 🌟](Topic_OpenAI.md) | 2024-05-06 |
| [Meta’s open source GPT-4 competitor Llama 3 is coming soon](https://the-decoder.com/metas-open-source-gpt-4-competitor-llama-3-is-coming-soon/) 🟢 | Meta is set to release Llama 3, an AI assistant intended to outperform its predecessors and compete with OpenAI’s GPT-4. It will debut with two preliminary versions before launching a comprehensive multimodal iteration in the summer. | [LLaMA 🦙](Topic_LLaMA.md), [Meta ♾](Topic_Meta.md), [GPT-4 and GPT-4 turbo 🚀](Topic_GPT-4_and_GPT-4_turbo.md), [OpenAI 🌟](Topic_OpenAI.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-04-15 |
| [Gemini 1.5 Pro Now Available in 180+ Countries; With Native Audio Understanding, System Instructions, JSON Mode and More](https://developers.googleblog.com/2024/04/gemini-15-pro-in-public-preview-with-new-features.html) 🟢 | Gemini 1.5 Pro has launched globally, offering cutting-edge native audio understanding and upgraded features such as a File API, system instructions, JSON mode for developers, along with advanced audio/video modalities, including video quiz capabilities. The update also introduces a highly performant text embedding model. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-04-15 |
| [GPT4 Turbo has been upgraded and is out of preview](https://platform.openai.com/docs/models/continuous-model-upgrades) 🟢 | The new GPT-4 Turbo, now with vision capabilities, supports vision requests via JSON mode and function calls, with knowledge updated until December 2023. | [GPT-4 and GPT-4 turbo 🚀](Topic_GPT-4_and_GPT-4_turbo.md), [OpenAI 🌟](Topic_OpenAI.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-04-15 |
| [x.AI Unveils it’s First Multimodal model, Grok-1.5 Vision](https://www.maginative.com/article/x-ai-unveils-its-first-multimodal-model-grok-1-5-vision/) 🟢 | x.AI, launched by Elon Musk, introduces Grok-1.5V, an advanced multimodal AI model with enhanced capabilities for analyzing visual data, including text, charts, and images. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Grok 🐦](Topic_Grok.md) | 2024-04-15 |
| [TikTok may add AI avatars that can make ads](https://www.theverge.com/2024/4/11/24127579/tiktok-ai-virtual-influencers-advertising) 🟢 | TikTok is investigating the integration of AI-powered avatars to deliver more personalized and engaging advertising experiences by aligning ad content with user interests. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-04-15 |
| [Introducing Stable Audio 2.0 from Stability AI](https://stability.ai/news/stable-audio-2-0) 🟢 | Stable Audio 2.0 introduces significant advancements in music generation AI, offering audio-to-audio conversion through natural language prompts and expanding creative possibilities with sound effects and improved style transfer. The latest version now supports the generation of high-quality (44.1 kHz) structured songs up to three minutes in length from concise prompts. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Stability AI ⚖️](Topic_Stability_AI.md) | 2024-04-08 |
| [OpenAI’s Sora just made its first music video and it’s like a psychedelic trip](https://www.techradar.com/computing/artificial-intelligence/openais-sora-just-made-its-first-music-video-and-its-like-a-psychedelic-trip) 🟢 | OpenAI has showcased the capabilities of its text-to-video engine, Sora, by creating a music video for August Kamp’s song “Worldweight” entirely through the engine’s capabilities. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI 🌟](Topic_OpenAI.md) | 2024-04-08 |
| [Introducing Stable Video 3D: Quality Novel View Synthesis and 3D Generation from Single Images](https://stability.ai/news/introducing-stable-video-3d) 🟢 | Stability AI has introduced Stable Video 3D (SV3D), a new generative model enhancing 3D tech with better quality and consistency. SV3D offers two versions: SV3D_u for single-image-based orbital videos without camera paths, and SV3D_p for more advanced 3D video creation using specified camera trajectories. For commercial use, it requires a Stability AI Membership, while non-commercial users can access the model weights through Hugging Face and consult the accompanying research paper. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Stability AI ⚖️](Topic_Stability_AI.md) | 2024-03-25 |
| [SIMA generalist AI agent for 3D virtual environments](https://deepmind.google/discover/blog/sima-generalist-ai-agent-for-3d-virtual-environments/) 🟢 | DeepMind has developed SIMA, a generalist AI agent designed to operate within 3D virtual environments, focusing on interpreting natural language and navigating complex problems rather than traditional game score maximization. SIMA has been trained across nine games from various genres and features a combination of pre-trained image recognition and memory-based models to process and act on both visual cues and linguistic instructions. | [Reinforcement learning 🎮](Topic_Reinforcement_learning.md), [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [DeepMind 🧩](Topic_DeepMind.md) | 2024-03-18 |
| [Midjourney debuts feature for generating consistent characters across multiple gen AI images](https://venturebeat.com/ai/midjourney-debuts-feature-for-generating-consistent-characters-across-multiple-gen-ai-images/) 🟢 | Midjourney has introduced an update enabling AI-generated character consistency in artwork through new tagging features. The “ — cref” tag allows users to reference a character image URL to maintain the character’s appearance across different scenes, while the “ — cw” tag adjusts the level of character consistency. This facilitates continuity in visual storytelling within the AI art community, although the precision of replication can vary. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Midjourney 🛤️](Topic_Midjourney.md) | 2024-03-18 |
| [Introducing the next generation of Claude](https://www.anthropic.com/news/claude-3-family) 🟢 | Anthropic has launched Claude 3, a new AI that surpasses GPT-4, with three models: Opus, Sonnet, and Haiku. Each supports a 200k context window, vision abilities, and multiple languages. Opus is touted as the top performer. Sonnet is integrated with Amazon Bedrock and Google Cloud’s Vertex AI, while Opus and Haiku are slated for future release along with new features like function calling and REPL. | [Claude 🖋️](Topic_Claude.md), [Anthropic 🌐](Topic_Anthropic.md), [Model release 🎉](Topic_Model_release.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Google 🔍](Topic_Google.md), [Amazon 🌳](Topic_Amazon.md), [GPT-4 and GPT-4 turbo 🚀](Topic_GPT-4_and_GPT-4_turbo.md) | 2024-03-11 |
| [OpenAI announces Sora](https://openai.com/sora) 🟢 | OpenAI has unveiled Sora, a novel AI video generator capable of crafting up to minute-long videos from textual prompts. Demonstrations showcase its ability to transform creative prompts into video content, emphasizing the synergy between AI and human creativity. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI 🌟](Topic_OpenAI.md) | 2024-02-19 |
| [V-JEPA: The next step toward advanced machine intelligence](https://ai.meta.com/blog/v-jepa-yann-lecun-ai-model-video-joint-embedding-predictive-architecture/) 🟢 | Yann LeCun proposes a machine learning paradigm, V-JEPA, to enable systems to build internal world models and learn intuitively like a human. Unlike conventional methods, V-JEPA employs a non-generative technique for video understanding, prioritizing abstract interpretation over detailed reproduction. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-02-19 |
| [Deepfake ‘face swap’ attacks surged 704% last year, study finds](https://thenextweb.com/news/deepfake-face-swap-attacks-increase) 🔴 | Deepfake technology advancements have resulted in a significant rise in ‘face swap’ attacks, with a 704% increase in the second half of the year, driven by accessible GenAI tools such as SwapFace and DeepFaceLive. These tools enhance the ability to produce undetectable deepfakes, facilitating anonymity and contributing to a spike in deepfake-enabled crimes, including a notable financial scam in Hong Kong. | [AI safety 🔐](Topic_AI_safety.md), [AI for images 🖼️](Topic_AI_for_images.md), [AI regulation 📜](Topic_AI_regulation.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2024-02-12 |
| [Labeling AI-Generated Images on Facebook, Instagram and Threads](https://about.fb.com/news/2024/02/labeling-ai-generated-images-on-facebook-instagram-and-threads/) 🟢 | Meta is implementing “Imagined with AI” labels for AI-generated content on Facebook and Instagram for greater transparency. While AI image labeling is available, Meta is developing detection for audio/video content and requires user disclosure until standards are established. Additionally, measures are being taken to ensure these transparency labels cannot be removed. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Meta ♾](Topic_Meta.md) | 2024-02-12 |
| [Voice cloning startup ElevenLabs lands $80M, achieves unicorn status](https://techcrunch.com/2024/01/22/voice-cloning-startup-elevenlabs-lands-80m-achieves-unicorn-status/) 🟢 | ElevenLabs has achieved unicorn status after securing an $80 million Series B round led by Andreessen Horowitz, raising their total funds to $101 million. Founded by Piotr Dabkowski and CEO Mati Staniszewski, the company specializes in realistic voice synthesis through a web app, targeting applications in audiobooks, gaming, and screen dubbing within the expanding audio media market. | [Text-to-speech 📢](Topic_Text-to-speech.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Funding 💰](Topic_Funding.md) | 2024-01-29 |
| [Google introduces Gemini](https://blog.google/technology/ai/google-gemini-ai/#capabilities) 🟢 | Google has introduced Gemini, a new model that comes in three sizes: Ultra, Pro, and Nano. Gemini is natively multimodal and outperforms other models in various academic benchmarks. Notably, Gemini Ultra achieves a groundbreaking score on a multitask language understanding test and excels in image benchmarks without relying on OCR systems. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Google Gemini 🌌](Topic_Google_Gemini.md), [Google 🔍](Topic_Google.md) | 2023-12-11 |
| [Pika Wows in Debut as AI Video Generator Takes Aim at Tech Giants](https://decrypt.co/207799/pika-ai-video-tool-blasts-out-of-beta) 🟢 | Pika Labs has released Pika 1.0, an impressive AI video generation tool. It has advanced features like Text-to-Video and Image-to-Video conversion. The company has also raised $55 million in funding. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Funding 💰](Topic_Funding.md) | 2023-12-04 |
| [Introducing SDXL Turbo: A Real-Time Text-to-Image Generation Model](https://stability.ai/news/stability-ai-sdxl-turbo) 🟢 | Stability AI introduces SDXL Turbo, a new text-to-image model that uses Adversarial Diffusion Distillation (ADD) to generate high-quality images rapidly and in a single step. It enables the quick and precise creation of 512 x 512 images in just over 200 milliseconds. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Stable Diffusion 🎨](Topic_Stable_Diffusion.md), [Stability AI ⚖️](Topic_Stability_AI.md) | 2023-12-04 |
| [Introducing Stable Video Diffusion — Stability AI](https://stability.ai/news/stable-video-diffusion-open-ai-video-model) 🟢 | Stability AI has introduced Stable Video Diffusion, a powerful foundation model for generative video. This model has the potential to generate customizable frames at varying frame rates and is publicly accessible on GitHub and Hugging Face for research purposes. | [Hugging Face 🤗](Topic_Hugging_Face.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Stability AI ⚖️](Topic_Stability_AI.md) | 2023-11-27 |
| [Off/Script launches an app to create and buy AI-designed fashion](https://techcrunch.com/2023/11/21/off-script-launches-ai-app/) 🟢 | Off/Script has launched a mobile app that allows users in the AI field to design, share, and potentially sell AI-generated fashion and product concepts. The platform uses voting to fund and produce the top-ranked ideas, working with a large network of manufacturers to bring these concepts to life. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Funding 💰](Topic_Funding.md) | 2023-11-27 |
| [DeepMind introduces Lyria, a model for music generation](https://deepmind.google/discover/blog/transforming-the-future-of-music-creation/) 🟢 | Google DeepMind’s AI music model, Lyria, is transforming the music creation process by producing exceptional quality music with customizable vocals. The ‘Dream Track’ experiment on YouTube enables artists to connect with fans through AI-generated voice and music, while AI tools enhance the creative journey for professionals in the music industry. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [DeepMind 🧩](Topic_DeepMind.md), [Google 🔍](Topic_Google.md) | 2023-11-20 |
| [Announcements from OpenAI DevDay](https://openai.com/blog/new-models-and-developer-products-announced-at-devday) 🟢 | OpenAI has introduced several new and improved models and APIs, including GPT-4 Turbo with a larger context window and lower prices, the ability to process images in the Chat Completions API, fine- tuning options for GPT-4 and GPT-3.5 Turbo, and the availability of DALL·E 3 via API. They have also introduced features like JSON mode, improved instruction following, and parallel function calling. Additionally, there are new options for text-to-speech and the creation of “GPT assistants.” OpenAI has also released the Whisper large-v3 model for automatic speech recognition. | [Whisper 🤫](Topic_Whisper.md), [Text-to-speech 📢](Topic_Text-to-speech.md), [Speech-to-text 🎤](Topic_Speech-to-text.md), [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [GPT-3, GPT-3.5, and GPT-3.5 turbo 💡](Topic_GPT-3_GPT-3.5_and_GPT-3.5_turbo.md), [GPT-4 and GPT-4 turbo 🚀](Topic_GPT-4_and_GPT-4_turbo.md), [OpenAI 🌟](Topic_OpenAI.md) | 2023-11-13 |
| [Google’s new Image and Source checker](https://blog.google/products/search/google-search-new-fact-checking-features/) 🟢 | Google has introduced new image and source verification tools that utilize AI to detect manipulated visuals and summarize credible sources. This aims to enhance transparency and provide faster access to background information, benefiting journalists investigating questionable images. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Google Gemini 🌌](Topic_Google_Gemini.md), [Google 🔍](Topic_Google.md) | 2023-10-30 |
| [Fuyu-8B: A Multimodal Architecture for AI Agents](https://www.adept.ai/blog/fuyu-8b) 🟢 | Adept has introduced Fuyu-8B, a powerful open-source vision-language model designed for comprehending and responding to questions regarding images, charts, diagrams, and documents. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [AI for images 🖼️](Topic_AI_for_images.md) | 2023-10-23 |
| [AI Just Deciphered an Ancient Herculaneum Scroll Without Unrolling It](https://decrypt.co/201411/ai-deciphered-herculaneum-scroll) 🟢 | A 21-year-old student from the University of Nebraska-Lincoln used AI to decipher Greek letters from an unopened scroll discovered after the eruption of Mount Vesuvius in 79 AD. By utilizing a machine learning algorithm, the student successfully identified Greek characters like “porphyras” meaning purple and won the Vesuvius Challenge. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-10-16 |
| [Scaling GAIA-1: 9-billion parameter generative world model for autonomous driving](https://wayve.ai/thinking/scaling-gaia-1/) 🟢 | GAIA-1 is a powerful 9B model designed for autonomous driving that generates synthetic data. It utilizes a video modeling approach, similar to LLMs, by predicting the next token. Trained on a substantial dataset, including 4,700 hours of London driving data, GAIA-1 is highly accurate in generating more data. | [AI datasets 📊](Topic_AI_datasets.md), [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Robotics 🤖](Topic_Robotics.md) | 2023-10-10 |
| [ChatGPT can now see, hear, and speak](https://openai.com/blog/chatgpt-can-now-see-hear-and-speak) 🟢 | OpenAI has introduced new voice and image capabilities to their AI assistant, ChatGPT. Users can now engage in natural voice conversations and receive relevant responses. The image feature enables users to show ChatGPT images for assistance in interpretation. | [Text-to-speech 📢](Topic_Text-to-speech.md), [Speech-to-text 🎤](Topic_Speech-to-text.md), [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI 🌟](Topic_OpenAI.md) | 2023-10-02 |
| [OpenAI announces DALL·E 3](https://openai.com/dall-e-3) 🟢 | OpenAI is launching DALL·E 3, an improved version that excels in following instructions, requires less prompt engineering, and can communicate with ChatGPT. This integration enables users to refine prompts for DALL·E 3 by describing their ideas to ChatGPT. Starting in October, DALL·E 3 will be available to ChatGPT Plus and Enterprise customers. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [ChatGPT 💬](Topic_ChatGPT.md), [OpenAI 🌟](Topic_OpenAI.md) | 2023-09-25 |
| [Announcing Microsoft Copilot, your everyday AI companion](https://blogs.microsoft.com/blog/2023/09/21/announcing-microsoft-copilot-your-everyday-ai-companion/) 🟢 | Microsoft Copilot will provide tailored assistance based on workplace data and web context. It enhances productivity and creativity in Windows 11, Microsoft 365, Edge, and Bing, while prioritizing privacy. Additionally, Bing and Edge users will enjoy a personalized experience with OpenAI’s DALL.E 3 model, including AI shopping and image creation. | [Microsoft 🪟](Topic_Microsoft.md), [OpenAI 🌟](Topic_OpenAI.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [AI for images 🖼️](Topic_AI_for_images.md) | 2023-09-25 |
| [How California is using AI to snuff out wildfires before they explode](https://edition.cnn.com/2023/09/23/us/fighting-wildfire-with-ai-california-climate/index.html) 🟢 | The California Department of Forestry and Fire Protection is utilizing AI technology to improve wildfire detection and response. Through the Alert California program, AI scans the wilderness for anomalies like smoke, alerting officials when fires are detected. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-09-25 |
| [Stable Audio](https://www.stableaudio.com/) 🟢 | London-based startup Stability AI, known for its AI model Stable Diffusion, has launched Stable Audio, an AI model that can generate high-quality commercial music with more control over synthesized audio. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Stable Diffusion 🎨](Topic_Stable_Diffusion.md), [Stability AI ⚖️](Topic_Stability_AI.md) | 2023-09-18 |
| [Adobe’s Firefly generative AI models are now generally available](https://techcrunch.com/2023/09/13/adobes-firefly-generative-ai-models-are-now-generally-available-get-pricing-plans/) 🟢 | Adobe has released commercially available generative AI models in their Creative Cloud, including a standalone web app called Firefly. The new “generative credits” system controls user interactions with Firefly’s AI models, with each click on ‘generate’ using one credit. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Model release 🎉](Topic_Model_release.md) | 2023-09-18 |
| [Ideogram launches AI image generator with impressive typography](https://venturebeat.com/ai/watch-out-midjourney-ideogram-launches-ai-image-generator-with-impressive-typography/) 🟢 | Ideogram is an alternative AI tool that excels in generating images with strong typography capabilities. It offers a unique feature of generating text within images, effectively addressing the common challenge faced by popular AI image generators. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-09-05 |
| [Identifying AI-generated images with SynthID](https://www.deepmind.com/blog/identifying-ai-generated-images-with-synthid) 🟢 | SynthID is a technology that uses imperceptible digital watermarks to identify AI- generated images, even after modifications like filters, color changes, and compression. | [AI safety 🔐](Topic_AI_safety.md), [AI and copyright ©️](Topic_AI_and_copyright.md), [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-09-05 |
| [Introducing a foundational multimodal model for speech translation](https://ai.meta.com/blog/seamless-m4t/) 🟢 | Meta has developed a powerful foundational model called SeamlessM4T that is capable of handling various text and speech tasks across 100 languages. It includes automatic speech recognition, speech-to-text translation, speech-to-speech translation, text-to-text translation, and text-to- speech translation, supporting a wide range of input and output languages. | [Text-to-speech 📢](Topic_Text-to-speech.md), [Speech-to-text 🎤](Topic_Speech-to-text.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Meta ♾](Topic_Meta.md) | 2023-08-28 |
| [Introducing IDEFICS: An Open Reproduction of State-of-the-art Visual Langage Model](https://huggingface.co/blog/idefics) 🟢 | IDEFICS is an impressive open-source visual language model with 9 billion and 80 billion parameters, based on DeepMind’s Flamingo. It offers the ability to describe images, generate stories, and answer image-related questions. It’s trained on diverse open datasets such as Wikipedia, Public Multimodal Dataset, LAION, and OBELICS. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [DeepMind 🧩](Topic_DeepMind.md) | 2023-08-28 |
| [AudioCraft: A simple one-stop shop for audio modeling](https://ai.meta.com/blog/audiocraft-musicgen-audiogen-encodec-generative-ai-audio/) 🟢 | Meta has released the code and weights for their AudioCraft models, including MusicGen and AudioGen. These models generate music and audio respectively, based on text-based user inputs. The release also includes the EnCodec decoder, which improves music quality. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Model release 🎉](Topic_Model_release.md), [Meta ♾](Topic_Meta.md) | 2023-08-07 |
| [NASA and IBM Openly Release Geospatial AI Foundation Model for NASA Earth Observation Data](https://www.earthdata.nasa.gov/news/impact-ibm-hls-foundation-model) 🟢 | NASA and IBM Research have collaborated to release the HLS Geospatial FM, an open-source geospatial AI model for Earth observation data. This model has shown success in various applications such as flood mapping, burn scar identification, and predicting crop yields. | [AI datasets 📊](Topic_AI_datasets.md), [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Model release 🎉](Topic_Model_release.md) | 2023-08-07 |
| [YouTube uses AI to summarize videos in latest test](https://www.theverge.com/2023/8/1/23815321/youtube-ai-video-summaries) 🟢 | YouTube is currently testing AI-generated video summaries to help viewers quickly determine the relevance of a video. The feature uses generative AI and will initially be available for English- language vlogs, shopping, and how-to videos on mobile devices. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Google Gemini 🌌](Topic_Google_Gemini.md), [Google 🔍](Topic_Google.md) | 2023-08-07 |
| [RT-2: New model translates vision and language into action](https://www.deepmind.com/blog/rt-2-new-model-translates-vision-and-language-into-action) 🟢 | Meta’s Robotic Transformer 2 (RT-2) is a vision-language-action model that combines web-scale capabilities with robotic control. It effectively recognizes visual and language patterns, generalizes emergent skills, and successfully leverages web-based data to learn new skills. | [Robotics 🤖](Topic_Robotics.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Meta ♾](Topic_Meta.md) | 2023-08-07 |
| [Bard’s latest update: more features, languages and countries](https://blog.google/products/bard/google-bard-new-features-update-july-2023/) 🟢 | Bard, a language model, has expanded its availability worldwide and now supports multiple languages. New features include the ability to listen to Bard’s responses, customize the tone and style of its output, pin and rename past conversations, export Python code to Replit and Google Colab, share responses with others, and utilize images in prompts with the help of Google Lens integration. | [Text-to-speech 📢](Topic_Text-to-speech.md), [AI for images 🖼️](Topic_AI_for_images.md), [AI for coding 👨‍💻](Topic_AI_for_coding.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Google Gemini 🌌](Topic_Google_Gemini.md), [Google 🔍](Topic_Google.md) | 2023-07-17 |
| [Shutterstock expands deal with OpenAI to build generative AI tools](https://techcrunch.com/2023/07/11/shutterstock-expands-deal-with-openai-to-build-generative-ai-tools/) 🟢 | OpenAI and Shutterstock have announced a partnership where OpenAI will use Shutterstock’s media library to train its AI models. In return, Shutterstock gains priority access to OpenAI’s advanced image transformation tools. Shutterstock is also working towards becoming a leader in generative AI by collaborating with top AI companies and compensating artists for their contributions to training the AI. | [AI and copyright ©️](Topic_AI_and_copyright.md), [AI datasets 📊](Topic_AI_datasets.md), [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI 🌟](Topic_OpenAI.md) | 2023-07-17 |
| [CMU Researchers Expand Ability of Robots To Learn From Videos](https://www.cs.cmu.edu/news/2023/VRB_robot_tasks) 🟢 | CMU researchers have developed a new method for teaching robots household tasks by training them to observe videos of humans completing those tasks. This approach can improve robots’ performance in cooking and cleaning by allowing them to master 12 different actions. | [Robotics 🤖](Topic_Robotics.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-06-26 |
| [Introducing Voicebox: The first generative AI model for speech to generalize across tasks with state-of-the-art performance](https://ai.facebook.com/blog/voicebox-generative-ai-model-speech/) 🟢 | Meta AI has developed Voicebox, a new model that uses a Flow Matching model to train on large and diverse datasets, enabling it to generate high-quality synthesized speech without specific training. The model can match audio styles, read text passages in multiple languages, and edit speech segments within audio recordings. The research paper and audio samples are available, but the model and code remain private to prevent misuse. | [Text-to-speech 📢](Topic_Text-to-speech.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Meta ♾](Topic_Meta.md) | 2023-06-26 |
| [Pixar Used AI to Stoke the Flames in ‘Elemental’](https://www.wired.com/story/pixar-elemental-artificial-intelligence-flames/) 🟢 | Pixar used neural style transfer and collaborated with Disney Research Studios to solve the challenge of capturing the ethereal nature of fire in their film “Elemental”. This ML innovation saved production time and reduced costs. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-06-26 |
| [LangChain & Vector Databases in Production Course](https://learn.activeloop.ai/courses/langchain) 🟢 | LangChain’s free AI course, LangChain & Vector Databases in Production, offers 50+ lessons and 10+ projects that cover API integration, prompt engineering, and production use. It teaches how to use Deep Lake, a versatile vector database for AI data that includes text, images, videos, and multiple embeddings. Basic Python knowledge, Jupyter Notebooks understanding, and GitHub familiarity are prerequisites. The course is designed to make AI practical and accessible, tailored to both experienced devs and enthusiasts. | [LangChain and LlamaIndex 🔗](Topic_LangChain_and_LlamaIndex.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-06-26 |
| [Google Lens can now search for skin conditions](https://techcrunch.com/2023/06/14/google-lens-can-now-search-for-skin-conditions/) 🟢 | Google Lens now has a feature that can identify skin conditions and other physical maladies by analyzing uploaded images. The feature can be integrated with chatbots to provide accurate answers about objects in photos. | [AI in healthcare 🏥](Topic_AI_in_healthcare.md), [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Google 🔍](Topic_Google.md) | 2023-06-20 |
| [Paul McCartney records Beatles song with help of AI](https://www.semafor.com/article/06/13/2023/paul-mccartney-beatles-song-ai) 🟢 | Paul McCartney used AI technology to restore John Lennon’s voice and record a Beatles song from a 1978 cassette tape labeled “For Paul.” This collaboration showcases the potential of AI in music preservation and opens up new opportunities for artists and fans in the future. | [Text-to-speech 📢](Topic_Text-to-speech.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-06-20 |
| [OpenAI’s plans according to Sam Altman](https://website-754fwhahs-humanloopml.vercel.app/blog/open_ai_talk) 🟢 | OpenAI plans to prioritize creating a cheaper and faster GPT-4, extending context windows, and releasing multimodality in 2024. However, they are currently limited by GPU shortages and are unable to make models millions of times bigger in the near future. The finetuning API will be extended to the latest models. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [AI Chips and GPUs 🖥️](Topic_AI_Chips_and_GPUs.md), [GPT-4 and GPT-4 turbo 🚀](Topic_GPT-4_and_GPT-4_turbo.md), [OpenAI 🌟](Topic_OpenAI.md) | 2023-06-06 |
| [Nvidia demo about speaking to AI game characters](https://www.theverge.com/2023/5/28/23740908/nvidia-ace-demo-voice-ai-npc-game-characters) 🟢 | Nvidia showcases a powerful AI-powered demo of conversational AI for game characters that enhances realism and engages players, providing game developers a tool to improve their games’ storytelling and overall engagement. | [NVIDIA 🎮](Topic_NVIDIA.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Text-to-speech 📢](Topic_Text-to-speech.md), [Speech-to-text 🎤](Topic_Speech-to-text.md) | 2023-06-06 |
| [Google’s new generative AI tool can jazz up product images](https://www.theverge.com/2023/5/23/23734129/google-product-studio-generative-ai-ads-merchant-center) 🟢 | Google’s new Product Studio uses generative AI to help Shopping merchants customize product images and improve their ad campaigns, with integration into the Merchant Center for added convenience. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Google 🔍](Topic_Google.md) | 2023-05-29 |
| [Stability AI releases StableStudio in latest push for open-source AI](https://www.theverge.com/2023/5/17/23726751/stability-ai-stablestudio-dreamstudio-stable-diffusion-artificial-intelligence) 🟢 | Stability AI has launched StableStudio as part of its open-source AI efforts. StableStudio is a new open-source variant of its DreamStudio AI text-to-image web app. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Stable Diffusion 🎨](Topic_Stable_Diffusion.md), [Stability AI ⚖️](Topic_Stability_AI.md) | 2023-05-22 |
| [Meta open-sources multisensory AI model that combines six types of data](https://www.theverge.com/2023/5/9/23716558/meta-imagebind-open-source-multisensory-modal-ai-model-research) 🟢 | Meta has unveiled ImageBind, an open-source AI model indexing six data types (visual, audio, text, thermal, depth, movement) for multisensory AI. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Meta ♾](Topic_Meta.md) | 2023-05-16 |
| [Artificial Intelligence Radio](https://artificialintelligenceradio.com/) 🟢 | A web radio with AI-generated music. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-05-02 |
| [With Bedrock, Amazon enters the generative AI race](https://techcrunch.com/2023/04/13/with-bedrock-amazon-enters-the-generative-ai-race/) 🟢 | Amazon Bedrock facilitates building AI-powered apps with pre-trained models from startups and AWS through an API to generate images, logos, and graphics. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Amazon 🌳](Topic_Amazon.md) | 2023-04-17 |
| [Meta introduced Segment Anything: Working toward the first foundation model for image segmentation](https://ai.facebook.com/blog/segment-anything-foundation-model-image-segmentation/) 🟢 | Introducing Segment Anything: democratizing image segmentation with SAM — a versatile, promptable model trained on a versatile dataset under Apache 2.0. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Model release 🎉](Topic_Model_release.md), [Meta ♾](Topic_Meta.md) | 2023-04-11 |
| [The AI-powered storytelling format](https://beta.tome.app/) 🟢 | Tome is an AI-powered storytelling platform that allows users to explain complex topics using narration and embeds from other sources. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-03-27 |
| [Gen-2 by Runway](https://research.runwayml.com/gen2) 🟢 | Gen-2 by Runway is an AI tool that can synthesize new videos using only an image, text prompt, or words without needing a camera or lights. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-03-27 |
| [GPT-4 is out](https://openai.com/product/gpt-4) 🟢 | GPT-4 is multimodal and accepts also images as inputs. It can handle over 25,000 words of text. GPT-4 can be tested with ChatGPT Plus. Otherwise, there’s an API waitlist. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [GPT-4 and GPT-4 turbo 🚀](Topic_GPT-4_and_GPT-4_turbo.md), [OpenAI 🌟](Topic_OpenAI.md) | 2023-03-20 |
| [MuAViC: The first audio-video speech translation benchmark](https://ai.facebook.com/blog/muavic-audio-visual-speech-translation-benchmark/) 🟢 | Using visual information to improve performance for English speech recognition tasks. | [Speech-to-text 🎤](Topic_Speech-to-text.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-03-13 |
| [YouTube’s new leader teases AI tools that can virtually swap creators’ outfits and locations](https://www.theverge.com/2023/3/1/23620143/youtube-ai-tool-features-ceo-neal-mohan-google-alphabet) 🟢 |  | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-03-06 |
| [Could Stable Diffusion Solve a Gap in Medical Imaging Data?](https://hai.stanford.edu/news/could-stable-diffusion-solve-gap-medical-imaging-data) 🟢 | Stanford scholars found a way to generate synthetic chest X-rays by fine-tuning the open-source Stable Diffusion foundation model. | [AI in healthcare 🏥](Topic_AI_in_healthcare.md), [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Stable Diffusion 🎨](Topic_Stable_Diffusion.md), [Stability AI ⚖️](Topic_Stability_AI.md) | 2023-02-20 |
| [Zero-shot image-to-text generation with BLIP-2](https://huggingface.co/blog/blip-2) 🟢 | The guide introduces BLIP-2 from Salesforce Research which enables a suite of state-of-the-art visual-language models that are now available in Hugging Face Transformers. | [Hugging Face 🤗](Topic_Hugging_Face.md), [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-02-20 |
| [Hugging Face releases SpeechT5](https://huggingface.co/blog/speecht5) 🟢 | a model able to do speech-to-text, text-to-speech, and speech-to-speech. | [Hugging Face 🤗](Topic_Hugging_Face.md), [Text-to-speech 📢](Topic_Text-to-speech.md), [Speech-to-text 🎤](Topic_Speech-to-text.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Model release 🎉](Topic_Model_release.md) | 2023-02-13 |
| [Runway new product Gen-1](https://research.runwayml.com/gen1) 🟢 | uses words and images to generate new videos out of existing ones. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-02-13 |
| [Dreamix: Video Diffusion Models are General Video Editors](https://dreamix-video-editing.github.io/) 🟢 |  | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-02-13 |
| [OpenAI has ramped up its hiring around the world](https://www.semafor.com/article/01/27/2023/openai-has-hired-an-army-of-contractors-to-make-basic-coding-obsolete) 🟢 | bringing on roughly 1,000 remote contractors over the past six months to create massive sets of images and audio clips to train AI tools. 60% of the contractors do data labeling and 40% are computer programmers. | [AI datasets 📊](Topic_AI_datasets.md), [AI for coding 👨‍💻](Topic_AI_for_coding.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI 🌟](Topic_OpenAI.md) | 2023-02-06 |
| [Noise2Music](https://noise2music.github.io/) 🟢 | a series of diffusion models trained to generate high-quality 30-second music clips from text prompts. The generated audio is able to faithfully reflect key elements of the text prompt such as genre, tempo, instruments, mood and era. | [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-02-06 |
| [Trends in AI in 2023](https://towardsai.net/p/l/trends-in-ai%E2%80%8A-%E2%80%8A2023-round-up) 🟢 | Predictions on language models, reinforcement learning, robotics, computer vision… | [Reinforcement learning 🎮](Topic_Reinforcement_learning.md), [Robotics 🤖](Topic_Robotics.md), [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md) | 2023-02-06 |
| [Shutterstock has rolled out a generative AI toolkit](https://techcrunch.com/2023/01/25/after-inking-its-openai-deal-shutterstock-rolls-out-a-generative-ai-toolkit-to-create-images-based-on-text-prompts/) 🔴 | to create images based on text prompts, while Getty Images is currently embroiled in a lawsuit against Stability AI. | [AI and copyright ©️](Topic_AI_and_copyright.md), [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [Stability AI ⚖️](Topic_Stability_AI.md) | 2023-01-30 |
| [Introducing Karlo, an Open Source DALL-E 2 (unCLIP)](https://huggingface.co/kakaobrain/karlo-v1-alpha)  | Karlo is a text-conditional image generation model based on OpenAI’s unCLIP architecture with the improvement over the standard super-resolution model from 64px to 256px, recovering high-frequency details only in the small number of denoising steps. | [AI for images 🖼️](Topic_AI_for_images.md), [Multimodal AI (image, video, audio) 📸](Topic_Multimodal_AI_(image_video_audio).md), [OpenAI 🌟](Topic_OpenAI.md) | 2023-01-23 |